"""
Response Analyzer Node.

Purpose: Analyze target responses for defense patterns
Role: First node after attack execution - extracts signals for downstream analysis
Dependencies: ResponseAnalyzer component (rule-based, no LLM)

Context Size: ~5KB input, ~1KB output
"""
import logging
from typing import Any

from services.snipers.deep_exploitation.state import DeepExploitationState
from services.snipers.adaptive_attack.components.response_analyzer import (
    ResponseAnalyzer,
)

logger = logging.getLogger(__name__)


async def response_analyzer_node(
    state: DeepExploitationState,
) -> dict[str, Any]:
    """
    Analyze target responses using rule-based pattern matching.

    This node is lightweight (no LLM) and runs quickly.
    Extracts defense signals for the failure analyzer.

    Args:
        state: Current state with target_responses

    Returns:
        State update with response_analysis dict
    """
    responses = state.get("target_responses", [])
    iteration = state.get("iteration", 0)

    logger.info(f"[ResponseAnalyzer] Iteration {iteration}: Analyzing {len(responses)} responses")

    if not responses:
        logger.warning("  No responses to analyze")
        return {
            "response_analysis": {
                "refusal_keywords": [],
                "policy_citations": False,
                "partial_compliance": False,
                "encoding_confusion": False,
                "tone": "unknown",
                "response_count": 0,
                "avg_length": 0,
            }
        }

    # Use existing ResponseAnalyzer component
    analyzer = ResponseAnalyzer()
    analysis = analyzer.analyze(responses)

    logger.info(f"  Tone: {analysis.get('tone', 'unknown')}")
    logger.info(f"  Refusal keywords: {len(analysis.get('refusal_keywords', []))}")
    logger.info(f"  Policy citations: {analysis.get('policy_citations', False)}")
    logger.info(f"  Encoding confusion: {analysis.get('encoding_confusion', False)}")

    return {"response_analysis": analysis}
