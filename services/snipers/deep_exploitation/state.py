"""
Deep Exploitation State Definition.

Purpose: Minimal state schema for context-efficient orchestration
Role: TypedDict state for LangGraph deep exploitation loop
Dependencies: Phase result types, chain discovery models

Design Principles:
    - Minimal state: Only pass what each node needs
    - Iteration history compressed: Just scores and chain names
    - No full response history: Only current batch
    - Observability via dedicated fields: chain_selection_result, etc.
"""
from typing import Any, Literal, TypedDict

from services.snipers.models import Phase1Result, Phase2Result, Phase3Result
from services.snipers.adaptive_attack.models.chain_discovery import (
    ChainDiscoveryContext,
    ChainDiscoveryDecision,
    ChainSelectionResult,
)
from services.snipers.adaptive_attack.models.adaptation_decision import (
    AdaptationDecision,
)


# Routing decisions after evaluation
EvaluationRoute = Literal["success", "continue", "exhausted", "error"]


class DeepExploitationState(TypedDict, total=False):
    """
    Minimal state for deep exploitation orchestration.

    Designed for context efficiency - each node receives only
    the fields it needs, not the entire state history.
    """

    # === Inputs (immutable) ===
    campaign_id: str
    target_url: str
    max_iterations: int
    success_threshold: float
    success_scorers: list[str]  # Which scorers must succeed

    # === Current Iteration ===
    iteration: int
    target_responses: list[str]  # Current batch ONLY (not history)

    # === Phase Results (current iteration only) ===
    phase1_result: Phase1Result | None
    phase2_result: Phase2Result | None
    phase3_result: Phase3Result | None

    # === Adaptation Tracking (compressed) ===
    tried_converters: list[list[str]]  # Just chain names
    tried_framings: list[str]  # Just framing names
    failure_cause: str | None

    # === Subagent Outputs (intermediate) ===
    response_analysis: dict[str, Any]  # From ResponseAnalyzer
    chain_discovery_context: ChainDiscoveryContext | None  # From FailureAnalyzer
    chain_discovery_decision: ChainDiscoveryDecision | None  # From ChainDiscovery
    chain_selection_result: ChainSelectionResult | None  # Chain selection details
    adaptation_decision: AdaptationDecision | None  # From StrategyGenerator

    # === Final Decisions (for execution) ===
    selected_chain: list[str]  # Converter chain to use
    custom_framing: dict[str, str] | None  # LLM-generated framing
    recon_custom_framing: dict[str, str] | None  # Recon-based framing
    preset_framing: str | None  # Fallback preset framing
    payload_guidance: str | None  # Instructions for payload generation

    # === Results ===
    is_successful: bool
    total_score: float
    best_score: float
    best_iteration: int

    # === Compressed History (for iteration tracking) ===
    iteration_history: list[dict[str, Any]]  # [{iteration, score, chain, success}]

    # === Control Flow ===
    route: EvaluationRoute | None  # Routing decision
    error: str | None
    completed: bool


def create_initial_state(
    campaign_id: str,
    target_url: str,
    max_iterations: int = 5,
    success_threshold: float = 0.8,
    success_scorers: list[str] | None = None,
) -> DeepExploitationState:
    """
    Create initial state for deep exploitation loop.

    Args:
        campaign_id: Campaign ID for intelligence loading
        target_url: Target endpoint URL
        max_iterations: Maximum attack iterations
        success_threshold: Minimum score for success (0.0-1.0)
        success_scorers: Scorers that must succeed (None = any)

    Returns:
        Initial DeepExploitationState
    """
    return DeepExploitationState(
        # Inputs
        campaign_id=campaign_id,
        target_url=target_url,
        max_iterations=max_iterations,
        success_threshold=success_threshold,
        success_scorers=success_scorers or [],
        # Current iteration
        iteration=0,
        target_responses=[],
        # Phase results
        phase1_result=None,
        phase2_result=None,
        phase3_result=None,
        # Adaptation tracking
        tried_converters=[],
        tried_framings=[],
        failure_cause=None,
        # Subagent outputs
        response_analysis={},
        chain_discovery_context=None,
        chain_discovery_decision=None,
        chain_selection_result=None,
        adaptation_decision=None,
        # Final decisions
        selected_chain=[],
        custom_framing=None,
        recon_custom_framing=None,
        preset_framing=None,
        payload_guidance=None,
        # Results
        is_successful=False,
        total_score=0.0,
        best_score=0.0,
        best_iteration=0,
        # History
        iteration_history=[],
        # Control flow
        route=None,
        error=None,
        completed=False,
    )
